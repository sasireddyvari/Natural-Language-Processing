{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Preprocessing Level 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0/ihgzh0ukhSNmpf93gzb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sasireddyvari/Natural-Language-Processing/blob/master/Text_Preprocessing_Level_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nFl19tkOuO_"
      },
      "source": [
        "import os\r\n",
        "import nltk\r\n",
        "import nltk.corpus\r\n",
        "import re\r\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize # Tokenization\r\n",
        "from nltk.stem import PorterStemmer,LancasterStemmer # Stemming : Normalize the words into base or root form. Not always the root form . Works based on cutting the edge or at the begining \r\n",
        "from nltk.probability import FreqDist # Frequency of words\r\n",
        "from nltk.corpus import stopwords # remove stopwords\r\n",
        "from nltk import blankline_tokenize # To find how many paras based on blank line\r\n",
        "from nltk.util import bigrams, trigrams, ngrams # 2 words, 3 words, n words\r\n",
        "from nltk import ne_chunk\r\n",
        "from nltk.stem import wordnet,WordNetLemmatizer # dictionary and Lemmatizer\r\n",
        "from nltk import ne_chunk\r\n",
        "\r\n",
        "text='''Passion is always a greater motivating force than Intelligence.\r\n",
        "An intelligent person will accomplish what he knows but an intelligent person will achive what he wants to.\r\n",
        "The English Wikipedia is the English-language edition of the free online encyclopedia Wikipedia. Founded on 15 January 2001, it is the first edition of Wikipedia and, as of April 2019, has the most articles of any edition.[2] As of October 2020, 11% of articles in all Wikipedias belong to the English-language edition. This share has gradually declined from more than 50 percent in 2003, due to the growth of Wikipedias in other languages.[3] As of 29 October 2020'''"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlFftQGqTOKi",
        "outputId": "21a34f0d-726d-456d-c1c5-edf0bf87180d"
      },
      "source": [
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGGZENyMSj0u"
      },
      "source": [
        "sentences= sent_tokenize(text)\r\n",
        "words = word_tokenize(text)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teFmWruWShk5"
      },
      "source": [
        "ps = PorterStemmer()\r\n",
        "wnl=WordNetLemmatizer()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTq7pvyOShfH",
        "outputId": "ec3d424d-ae4c-4bed-dae0-5bf10e29ad1d"
      },
      "source": [
        "corpus = []\r\n",
        "for i in range(len(sentences)):\r\n",
        "  review = re.sub('[^a-zA-Z]', ' ', sentences[i])\r\n",
        "  review = review.lower()\r\n",
        "  review = review.split()\r\n",
        "  review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\r\n",
        "  review = ' '.join(review)\r\n",
        "  corpus.append(review)\r\n",
        "\r\n",
        "corpus"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['passion alway greater motiv forc intellig',\n",
              " 'intellig person accomplish know intellig person achiv want',\n",
              " 'english wikipedia english languag edit free onlin encyclopedia wikipedia',\n",
              " 'found januari first edit wikipedia april articl edit',\n",
              " 'octob articl wikipedia belong english languag edit',\n",
              " 'share gradual declin percent due growth wikipedia languag',\n",
              " 'octob']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njR2fWQuTdgC",
        "outputId": "9efc61b5-a3cf-4629-eba9-d7b1de2433c8"
      },
      "source": [
        "corpus=[]\r\n",
        "for i in range(len(sentences)):\r\n",
        "  review = re.sub('[^a-zA-Z]', ' ', sentences[i])\r\n",
        "  review = review.lower()\r\n",
        "  review = review.split()\r\n",
        "  review = [wnl.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\r\n",
        "  review = ' '.join(review)\r\n",
        "  corpus.append(review)\r\n",
        "\r\n",
        "corpus"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['passion always greater motivating force intelligence',\n",
              " 'intelligent person accomplish know intelligent person achive want',\n",
              " 'english wikipedia english language edition free online encyclopedia wikipedia',\n",
              " 'founded january first edition wikipedia april article edition',\n",
              " 'october article wikipedias belong english language edition',\n",
              " 'share gradually declined percent due growth wikipedias language',\n",
              " 'october']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqYfcixeSVmT"
      },
      "source": [
        "**Bag of Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gmxJPITP0Zy"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer # Count vectorizer is responsible for creating matrix of bag of words by filtering, sorting "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxA9x61xP0XJ"
      },
      "source": [
        "cv=CountVectorizer()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSlmmK39P0VG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a8ab78-83ca-472c-9823-8d2c7a3635a1"
      },
      "source": [
        "x=cv.fit_transform(corpus).toarray()\r\n",
        "x # document matrix with bag of words . Disadvantage is no proper semantics for good and bad . Both are equally given and cant give much semantics to it."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0],\n",
              "       [0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOdgwdLZSsss",
        "outputId": "a921e839-6f10-4132-ae1c-0356b2e934af"
      },
      "source": [
        "x.shape # since 7 sentences"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIu0bt95X06R"
      },
      "source": [
        "**TF * IDF** \r\n",
        "- **Term Frequency** : No of repetitions of word in a sentence/ Total no of words in sentence\r\n",
        "\r\n",
        "- **Inverse Document Frequency**: log(No of sentences/No of sentences containing word)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcAP930aP0Se"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OzV5VHjP0QV"
      },
      "source": [
        "tf=TfidfVectorizer()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzyUOanDP0N7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8445b3f5-4666-42ce-f797-e9bb63598e0b"
      },
      "source": [
        "x= tf.fit_transform(corpus).toarray()\r\n",
        "x.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIZBGW-eP0Lw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eADSLReIP0Jq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SMmA354P0Ho"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQmnHxq9P0E6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}